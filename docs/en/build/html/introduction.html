

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>Introduction &mdash; Gerapy 0.9.1 documentation</title>
  

  
  
  
  

  
  <script type="text/javascript" src="_static/js/modernizr.min.js"></script>
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="./" src="_static/documentation_options.js"></script>
        <script type="text/javascript" src="_static/jquery.js"></script>
        <script type="text/javascript" src="_static/underscore.js"></script>
        <script type="text/javascript" src="_static/doctools.js"></script>
        <script type="text/javascript" src="_static/language_data.js"></script>
        <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    
    <script type="text/javascript" src="_static/js/theme.js"></script>

    

  
  <link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="Installation" href="installation.html" />
    <link rel="prev" title="Welcome to sphinx_demo’s documentation!" href="index.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="index.html" class="icon icon-home"> Gerapy
          

          
          </a>

          
            
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <ul class="current">
<li class="toctree-l1 current"><a class="current reference internal" href="#">介绍</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#scrapy">Scrapy</a></li>
<li class="toctree-l2"><a class="reference internal" href="#scrapyd">Scrapyd</a></li>
<li class="toctree-l2"><a class="reference internal" href="#scrapyd-client">Scrapyd-Client</a></li>
<li class="toctree-l2"><a class="reference internal" href="#scrapyd-api">Scrapyd-API</a></li>
<li class="toctree-l2"><a class="reference internal" href="#gerapy">Gerapy</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="installation.html">安装</a></li>
<li class="toctree-l1"><a class="reference internal" href="usage.html">使用</a></li>
<li class="toctree-l1"><a class="reference internal" href="docker.html">Docker</a></li>
<li class="toctree-l1"><a class="reference internal" href="contributing.html">贡献</a></li>
<li class="toctree-l1"><a class="reference internal" href="maintainers.html">作者</a></li>
<li class="toctree-l1"><a class="reference internal" href="license.html">协议</a></li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="index.html">Gerapy</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="index.html">Docs</a> &raquo;</li>
        
      <li>Introduction</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
            
            <a href="_sources/introduction.md.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  
<style>
/* CSS overrides for sphinx_rtd_theme */

/* 24px margin */
.nbinput.nblast.container,
.nboutput.nblast.container {
    margin-bottom: 19px;  /* padding has already 5px */
}

/* ... except between code cells! */
.nblast.container + .nbinput.container {
    margin-top: -19px;
}

.admonition > p:before {
    margin-right: 4px;  /* make room for the exclamation icon */
}

/* Fix math alignment, see https://github.com/rtfd/sphinx_rtd_theme/pull/686 */
.math {
    text-align: unset;
}
</style>
<div class="section" id="introduction">
<h1>Introduction<a class="headerlink" href="#introduction" title="Permalink to this headline">¶</a></h1>
<p>A small partner who has worked as a crawler with Python may have been exposed to <a class="reference external" href="https://github.com/scrapy/scrapy">Scrapy</a>. Scrapy is indeed a very powerful crawler framework. It has high crawling efficiency and good scalability. It is basically a necessary tool for developing crawlers using Python.</p>
<div class="section" id="scrapy">
<h2>Scrapy<a class="headerlink" href="#scrapy" title="Permalink to this headline">¶</a></h2>
<p>If you use Scrapy as a crawler, then of course we can use our own host to crawl when crawling, but when the crawl is very large, we can’t run the crawler on our own machine, a good one. The method is to deploy Scrapy to a remote server for execution.</p>
</div>
<div class="section" id="scrapyd">
<h2>Scrapyd<a class="headerlink" href="#scrapyd" title="Permalink to this headline">¶</a></h2>
<p>At this time, you might use <a class="reference external" href="https://github.com/scrapy/scrapyd">Scrapyd</a>. With it, we only need to install Scrapyd on the remote server and start the service. We can deploy the Scrapy project we wrote. Go to the remote host. In addition, Scrapyd provides a variety of operations <a class="reference external" href="http://scrapyd.readthedocs.io/en/stable/api.html">API</a>, which gives you free control over the operation of the Scrapy project. For example, we installed Scrapyd on IP 88.88. On the .88.88 server, then deploy the Scrapy project. At this time, we can control the operation of the Scrapy project by requesting the API. The command is as follows:</p>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span>curl http://88.88.88.88:6800/schedule.json -d <span class="nv">project</span><span class="o">=</span>myproject -d <span class="nv">spider</span><span class="o">=</span>myspider
</pre></div>
</div>
<p>This is equivalent to launching the myspider crawler for the myproject project, instead of using the command line to launch the crawler, and Scrapyd also provides a set of APIs for viewing crawler status, canceling crawler tasks, adding crawler versions, removing crawler versions, and more. So, with Scrapyd, we can control the crawler’s operation through the API and get rid of the command line dependencies.</p>
</div>
<div class="section" id="scrapyd-client">
<h2>Scrapyd-Client<a class="headerlink" href="#scrapyd-client" title="Permalink to this headline">¶</a></h2>
<p>The crawler deployment is still a hassle because we need to upload the crawler code to the remote server. This process involves two processes of packaging and uploading. In Scrapyd, the API for this deployment is called, which is called addversion, but the content it receives is Egg package file, so to use this interface, we have to package our Scrapy project into an egg file, and then use the file upload method to request the addversion interface to complete the upload, this process is more cumbersome, so it has appeared A tool called <a class="reference external" href="https://github.com/scrapy/scrapyd-client">Scrapyd-Client</a>, with its scrapyd-deploy command, we can complete two functions of packaging and uploading, which is a convenient step.</p>
</div>
<div class="section" id="scrapyd-api">
<h2>Scrapyd-API<a class="headerlink" href="#scrapyd-api" title="Permalink to this headline">¶</a></h2>
<p>So we have solved the deployment problem. In the end, what if we want to see the running status of Scrapy on the server in real time? As I said earlier, of course, I am requesting Scrapyd’s API. If we want to use Python programs to control it? We also use the requests library to request these APIs again and again? This is too much trouble, so in order to solve this need, <a class="reference external" href="https://github.com/djm/python-scrapyd-api">Scrapyd-API</a> has appeared again, with it we can use only simple Python code It is possible to monitor and run the Scrapy project:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">From</span> <span class="n">scrapyd_api</span> <span class="kn">import</span> <span class="nn">ScrapydAPI</span>
<span class="n">Scrapyd</span> <span class="o">=</span> <span class="n">ScrapydAPI</span><span class="p">(</span><span class="s1">&#39;http://88.888.88.88:6800&#39;</span><span class="p">)</span>
<span class="n">Scrapyd</span><span class="o">.</span><span class="n">list_jobs</span><span class="p">(</span><span class="s1">&#39;project_name&#39;</span><span class="p">)</span>
</pre></div>
</div>
<p>The result of this return is the operation of each Scrapy project. E.g:</p>
<div class="highlight-json notranslate"><div class="highlight"><pre><span></span>{
    &#39;pending&#39;: [
    ],
    &#39;running&#39;: [
        {
            &#39;id&#39;: u&#39;14a65...b27ce&#39;,
            &#39;spider&#39;: u&#39;spider_name&#39;,
            &#39;start_time&#39;: u&#39;2018-01-17 22:45:31.975358&#39;
        },
    ],
    &#39;finished&#39;: [
        {
            &#39;id&#39;: &#39;34c23...b21ba&#39;,
            &#39;spider&#39;: &#39;spider_name&#39;,
            &#39;start_time&#39;: &#39;2018-01-11 22:45:31.975358&#39;,
            &#39;end_time&#39;: &#39;2018-01-17 14:01:18.209680&#39;
        }
    ]
}
</pre></div>
</div>
<p>This way we can see the running status of the Scrapy crawler.</p>
<p>So, with them, what we can accomplish is:</p>
<ul class="simple">
<li><p>Complete the deployment of Scrapy projects with Scrapyd</p></li>
<li><p>Control the startup and status monitoring of Scrapy projects through the API provided by Scrapyd</p></li>
<li><p>Simplify deployment of Scrapy projects with Scrapyd-Client</p></li>
<li><p>Control Scrapy project via Python via Scrapyd-API</p></li>
</ul>
<p>Is it more convenient?</p>
</div>
<div class="section" id="gerapy">
<h2>Gerapy<a class="headerlink" href="#gerapy" title="Permalink to this headline">¶</a></h2>
<p>but? Is it really convenient to achieve it? Certainly not! If all of this, from Scrapy’s deployment, startup to monitoring, log viewing, we only need a few clicks of the mouse and keyboard to complete, isn’t it beautiful? In addition, we can visually configure various timing tasks and monitoring functions to conveniently schedule Scrapy crawler projects. Or, even Scrapy code can automatically generate it for you, isn’t that cool?</p>
<p>There is motivation for demand, yes, <a class="reference external" href="https://github.com/Gerapy/Gerapy">Gerapy</a> was born.</p>
<p>Gerapy is a distributed crawler management framework that supports Python 3, based on Scrapy, Scrapyd, Scrapyd-Client, Scrapy-Redis, Scrapyd-API, Scrapy-Splash, Django, Vue.js. Gerapy can help us:</p>
<ul class="simple">
<li><p>More convenient control of crawler runs</p></li>
<li><p>View reptile status more intuitively</p></li>
<li><p>View crawl results in more real time</p></li>
<li><p>Easier timing tasks</p></li>
<li><p>Easier project deployment</p></li>
<li><p>More unified host management</p></li>
<li><p>Write crawler code more easily</p></li>
</ul>
<p>With it, the management of the Scrapy distributed crawler project is no longer difficult.</p>
</div>
</div>


           </div>
           
          </div>
          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="installation.html" class="btn btn-neutral float-right" title="Installation" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right"></span></a>
      
      
        <a href="index.html" class="btn btn-neutral float-left" title="Welcome to sphinx_demo’s documentation!" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left"></span> Previous</a>
      
    </div>
  

  <hr/>

  <div role="contentinfo">
    <p>
        &copy; Copyright 2019, Germey

    </p>
  </div>
  Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>
      </div>

    </section>

  </div>
  


  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
   

</body>
</html>